{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7cbda9-0eb6-43ca-9a3c-b63fb7002d28",
   "metadata": {},
   "source": [
    "# Comparison of performance by all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99080685-4012-4c61-9c18-72f02d8edb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93547be-1d91-409f-be60-e9a3132fb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comparison_Models():\n",
    "    models = ['Linear Regression', 'SVM', 'Random Forest', 'RNN', 'LSTM']\n",
    "    mse_values = [linear_mse, svm_mse, rf_mse, RNN_mse, LSTM_mse]\n",
    "    rmse_values = [linear_rmse, svm_rmse, rf_rmse, RNN_rmse, LSTM_rmse]\n",
    "    mae_values = [linear_mae, svm_mae, rf_mae, RNN_mae, LSTM_mae]\n",
    "    \n",
    "    # Function to plot the comparison of metrics\n",
    "    def plot_comparison(models, values, metric_name):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(models, values, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "        plt.title(f'Model Comparison - {metric_name}')\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel(metric_name)\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot the comparison of MSE\n",
    "    plot_comparison(models, mse_values, 'Mean Squared Error (MSE)')\n",
    "    \n",
    "    # Plot the comparison of RMSE\n",
    "    plot_comparison(models, rmse_values, 'Root Mean Squared Error (RMSE)')\n",
    "    \n",
    "    # Plot the comparison of MAE\n",
    "    plot_comparison(models, mae_values, 'Mean Absolute Error (MAE)')\n",
    "    \n",
    "    # Determine the best performing model\n",
    "    # Lower values of MSE, RMSE, and MAE indicate better performance\n",
    "    \n",
    "    best_model_index_mse = np.argmin(mse_values)\n",
    "    best_model_index_rmse = np.argmin(rmse_values)\n",
    "    best_model_index_mae = np.argmin(mae_values)\n",
    "    \n",
    "    best_model_mse = models[best_model_index_mse]\n",
    "    best_model_rmse = models[best_model_index_rmse]\n",
    "    best_model_mae = models[best_model_index_mae]\n",
    "    \n",
    "    print(f'Best model based on MSE: {best_model_mse}')\n",
    "    print(f'Best model based on RMSE: {best_model_rmse}')\n",
    "    print(f'Best model based on MAE: {best_model_mae}')\n",
    "    \n",
    "    # To decide on an overall best model, you can take a majority vote or consider the most important metric for your use case\n",
    "    best_models = [best_model_mse, best_model_rmse, best_model_mae]\n",
    "    best_model_overall = max(set(best_models), key=best_models.count)\n",
    "    \n",
    "    print(f'Overall best performing model: {best_model_overall}')\n",
    "\n",
    "    return best_model_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ab6f7e-eeec-413a-bb6e-2b42cab5b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot actual vs. predicted values for each model in separate subplots\n",
    "def Visualize_Predictions(y_test, y_preds, models):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Define colors for y_pred lines\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "    \n",
    "    for ax, y_pred, model, color in zip(axes, y_preds, models, colors):\n",
    "        ax.plot(y_test, label='True Value', color='gray')\n",
    "        ax.plot(y_pred, label=f'{model} Value', color=color)\n",
    "        ax.set_title(f'{model} Prediction')\n",
    "        ax.set_xlabel('Time Scale')\n",
    "        ax.set_ylabel('Scaled USD')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # Plotting the actual values only plot in the last subplot\n",
    "    axes[-1].plot(y_test, label='True Value', color='gray')\n",
    "    axes[-1].set_title('Actual Values')\n",
    "    axes[-1].set_xlabel('Time Scale')\n",
    "    axes[-1].set_ylabel('Scaled USD')\n",
    "    axes[-1].legend()\n",
    "    axes[-1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510b357-16ed-4c5b-b611-a806ca2d114e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
