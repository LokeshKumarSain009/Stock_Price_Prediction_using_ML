{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f712fb8d-a0f0-4ec9-ba98-9dd170c89eb5",
   "metadata": {},
   "source": [
    "# Fetching news articles from \"News API\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71938bb8-ce84-45a7-93f9-958ddbc16b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738996c1-6098-4cce-8d66-fcb092a62ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a API Key from newsapi website :  https://newsapi.org/\n",
    "api_key=\"1cc968acf6c94176b3ee0d6b76b05c04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871c86e7-3064-4be2-bd2c-4ec8d0f2782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8f2891-4bc2-4d15-b769-a26781a53703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_sentiment_analysis(stock,ticker):\n",
    "   # Function to fetch news articles\n",
    "    def fetch_news(api_key, query, max_results=100):\n",
    "        url = f'https://newsapi.org/v2/everything?q={query}&pageSize={max_results}&apiKey={api_key}'\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        articles = data.get('articles', [])\n",
    "        return articles \n",
    "    \n",
    "    # Fetch news articles for Stock\n",
    "    query = stock + \" , \" + ticker\n",
    "    articles = fetch_news(api_key, query)\n",
    "    \n",
    "    # Extract datetime, content\n",
    "    news_data = [{'datetime': article.get('publishedAt', ''),\n",
    "                  'content': article.get('content', '')} for article in articles]\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    news_df = pd.DataFrame(news_data)\n",
    "    \n",
    "    # Remove articles with empty content\n",
    "    news_df = news_df[(news_df['content'].str.lower() != '[removed]') & (news_df['content'] != '')]\n",
    "    news_df=news_df.reset_index()\n",
    "    \n",
    "    # Function to calculate sentiment scores\n",
    "    def get_sentiment_scores(text):\n",
    "        if not text:\n",
    "            return 0\n",
    "        scores = analyzer.polarity_scores(text)\n",
    "        return scores['compound']\n",
    "\n",
    "    #compound_score=scores['compound']\n",
    "    # Function to classify sentiment\n",
    "    def classify_sentiment(score):\n",
    "        if score >= 0.05:\n",
    "            return 'Positive'\n",
    "        elif score <= -0.05:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    \n",
    "    # Calculate sentiment scores and classify sentiment\n",
    "    news_df['sentiment_score'] = news_df['content'].apply(get_sentiment_scores)\n",
    "    news_df['sentiment'] = news_df['sentiment_score'].apply(classify_sentiment)\n",
    "\n",
    "    \n",
    "    return news_data,news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b64628-3d9a-4683-b708-4f771bfcb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize_News(news_data,news_df):\n",
    "    # Word Cloud for all articles\n",
    "    all_text = ' '.join(news_df['content'].dropna())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for All Articles')\n",
    "    plt.show()\n",
    "    \n",
    "    # Bar Chart for Classified Sentiments\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='sentiment', data=news_df, palette='viridis', hue='sentiment', legend = False)\n",
    "    plt.title('Bar Chart of Classified Sentiments')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # Pie Chart for Sentiment Distribution\n",
    "    sentiment_counts = news_df['sentiment'].value_counts()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('viridis', len(sentiment_counts)))\n",
    "    plt.title('Pie Chart of Sentiment Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd1b6e-1a3b-4ffe-89d2-294479511dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5505bb0-3785-4f3a-9ca9-5551d415d183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7cb26c-196a-4f05-98a8-9d10c92736b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76c096-e8da-44e7-8249-0c128236b305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ab1ac-8d98-43a7-8662-594cfbdec5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
